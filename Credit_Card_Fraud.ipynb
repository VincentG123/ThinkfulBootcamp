{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with importing the data and taking a peek..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credit_fraud = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "credit_fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_fraud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So apparently, this data has already been PCA'd and the feartures are now anonymous except for time, amount, and class (normal/not fraud and fraud). \n",
    "\n",
    "I'm going to look at the the counts. It's supposed to be really skewed towards the normal/not fraud category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x102f59128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktTd/wfPdsKHs6aZdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b9073c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(credit_fraud['Class'], sort = True).sort_index()\n",
    "\n",
    "# count_classes = pd.value_counts(credit_fraud['Class'])\n",
    "print(count_classes)\n",
    "\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it is VERY, VERY skewed... \n",
    "\n",
    "I'm going to address this skewedness by undersampling the non-fraud data points. But first, I'm going to normalize the amount column and drop the time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Class  normAmount  \n",
       "0      0    0.244964  \n",
       "1      0   -0.342475  \n",
       "2      0    1.160686  \n",
       "3      0    0.140534  \n",
       "4      0   -0.073403  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "credit_fraud['normAmount'] = StandardScaler().fit_transform(credit_fraud['Amount'].values.reshape(-1, 1))\n",
    "credit_fraud = credit_fraud.drop(['Time','Amount'],axis=1)\n",
    "credit_fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling the non-fraud data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the two data frames\n",
    "\n",
    "X = credit_fraud.loc[:, credit_fraud.columns != 'Class']\n",
    "y = credit_fraud.loc[:, credit_fraud.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions:  0.5\n",
      "Percentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    }
   ],
   "source": [
    "# Number of data points in the minority class\n",
    "number_records_fraud = len(credit_fraud[credit_fraud.Class == 1])\n",
    "\n",
    "# Getting the index numbers of all the fraud data points\n",
    "fraud_indices = np.array(credit_fraud[credit_fraud.Class == 1].index)\n",
    "\n",
    "# Picking the indices of the normal/non-fraud classes\n",
    "normal_indices = credit_fraud[credit_fraud.Class == 0].index\n",
    "\n",
    "# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# Appending the 2 indices\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "# Use the indices to under sample dataset\n",
    "under_sample_data = credit_fraud.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.loc[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.loc[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "# Showing ratio\n",
    "print(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
    "print(\"Total number of transactions in resampled data: \", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm going to break it up into training and testing sets. The test size will be 30% of the entire set and the training size will be 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Splitting the whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "# Splitting the undersampled dataset\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n",
    "                                                                                                   ,y_undersample\n",
    "                                                                                                   ,test_size = 0.3,random_state = 0)\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this next section, he is trying to find the best C value for the Logistic Regression. He is using a function to go through 5 different values: 0.01, 0.1, 1, 10, and 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(len(y_train_data),5,shuffle=False) \n",
    "\n",
    "    # Different C parameters\n",
    "    c_param_range = [0.01,0.1,1,10,100]\n",
    "    \n",
    "    # Create a data frame with an\n",
    "\n",
    "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "\n",
    "    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-------------------------------------------')\n",
    "        print('C parameter: ', c_param)\n",
    "        print('-------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        recall_accs = []\n",
    "        for iteration, indices in enumerate(fold,start=1):\n",
    "\n",
    "            # Call the logistic regression model with a certain C parameter\n",
    "            # What is the C parameter and the penalty again?\n",
    "            lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
    "\n",
    "            # Use the training data to fit the model. In this case, we use the portion of the \n",
    "            # fold to train the model with indices[0]. We then predict on the portion assigned \n",
    "            # as the 'test cross validation' with indices[1]\n",
    "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
    "\n",
    "            # Predict values using the test indices in the training data\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "\n",
    "            # Calculate the recall score and append it to a list for recall scores representing \n",
    "            # the current c_parameter\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration,': recall score = ', recall_acc)\n",
    "\n",
    "        # The mean value of those recall scores is the metric we want to save and get hold of.\n",
    "        results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score ', np.mean(recall_accs))\n",
    "        print('')\n",
    "\n",
    "    # This finds the best C value by using idxmax function to get the index of the highest \n",
    "    # mean recall score and the C_parameter column\n",
    "    \n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "    \n",
    "    # Finally, we can check which C parameter is the best amongst the chosen.\n",
    "    print('*********************************************************************************')\n",
    "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "C parameter:  0.01\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.931506849315\n",
      "Iteration  2 : recall score =  0.917808219178\n",
      "Iteration  3 : recall score =  1.0\n",
      "Iteration  4 : recall score =  0.972972972973\n",
      "Iteration  5 : recall score =  0.954545454545\n",
      "\n",
      "Mean recall score  0.955366699202\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  0.1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.849315068493\n",
      "Iteration  2 : recall score =  0.86301369863\n",
      "Iteration  3 : recall score =  0.966101694915\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.909090909091\n",
      "\n",
      "Mean recall score  0.906693463415\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.86301369863\n",
      "Iteration  2 : recall score =  0.904109589041\n",
      "Iteration  3 : recall score =  0.983050847458\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.924242424242\n",
      "\n",
      "Mean recall score  0.924072501063\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  10\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.86301369863\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.983050847458\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.924242424242\n",
      "\n",
      "Mean recall score  0.921332775036\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  100\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.876712328767\n",
      "Iteration  2 : recall score =  0.890410958904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:40: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.983050847458\n",
      "Iteration  4 : recall score =  0.945945945946\n",
      "Iteration  5 : recall score =  0.924242424242\n",
      "\n",
      "Mean recall score  0.924072501063\n",
      "\n",
      "*********************************************************************************\n",
      "Best model to choose from cross validation is with C parameter =  0.01\n",
      "*********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using the below to find what all of these functions do... \n",
    "\n",
    "KFold creates indices that I can then use with an indexer to create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=688, n_folds=5, shuffle=False, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "print(KFold(len(y_train_undersample),5,shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C_parameter Mean recall score\n",
      "0         0.01               NaN\n",
      "1         0.10               NaN\n",
      "2         1.00               NaN\n",
      "3        10.00               NaN\n",
      "4       100.00               NaN\n"
     ]
    }
   ],
   "source": [
    "c_param_range = [0.01,0.1,1,10,100]\n",
    "\n",
    "# Not sure what the index parameter does... right now range(len(c_param_range),2) gives me []\n",
    "# And when I take it out completely, it still works... so not sure why index = [] was\n",
    "# Necessary...\n",
    "\n",
    "results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
    "\n",
    "# Fills in C_parameter column with c_param_range numbers\n",
    "\n",
    "results_table['C_parameter'] = c_param_range\n",
    "\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5, step=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So KFold creates different groups of index numbers. In this case it took the number of rows\n",
    "# possible and then broke it up into 5 groups. It then takes out each group one at a time to \n",
    "# serve as the test group and combines the remaining groups into a bigger group that serves\n",
    "# as the training group. When it is done doing it's work, you will have 5 sets of different\n",
    "# test/train group pairings.\n",
    "\n",
    "fold = KFold(len(y_train_undersample),5,shuffle=False)\n",
    "fold_list = list(enumerate(fold,start=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (array([138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
       "          151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "          164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
       "          177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
       "          190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
       "          203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
       "          216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "          229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "          242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
       "          255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
       "          268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
       "          281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "          294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
       "          307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
       "          320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
       "          333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345,\n",
       "          346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
       "          359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371,\n",
       "          372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
       "          385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
       "          398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
       "          411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
       "          424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
       "          437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
       "          450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "          463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "          476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
       "          489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
       "          502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514,\n",
       "          515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527,\n",
       "          528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540,\n",
       "          541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
       "          554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566,\n",
       "          567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579,\n",
       "          580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592,\n",
       "          593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605,\n",
       "          606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618,\n",
       "          619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631,\n",
       "          632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644,\n",
       "          645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
       "          658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670,\n",
       "          671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683,\n",
       "          684, 685, 686, 687]),\n",
       "   array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "           13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "           26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "           39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "           52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "           65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "           78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "           91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "          104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "          117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "          130, 131, 132, 133, 134, 135, 136, 137]))),\n",
       " (2, (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "           13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "           26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "           39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "           52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "           65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "           78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "           91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "          104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "          117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "          130, 131, 132, 133, 134, 135, 136, 137, 276, 277, 278, 279, 280,\n",
       "          281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "          294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
       "          307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319,\n",
       "          320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332,\n",
       "          333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345,\n",
       "          346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358,\n",
       "          359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371,\n",
       "          372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
       "          385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
       "          398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
       "          411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
       "          424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
       "          437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
       "          450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "          463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "          476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
       "          489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
       "          502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514,\n",
       "          515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527,\n",
       "          528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540,\n",
       "          541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
       "          554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566,\n",
       "          567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579,\n",
       "          580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592,\n",
       "          593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605,\n",
       "          606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618,\n",
       "          619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631,\n",
       "          632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644,\n",
       "          645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
       "          658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670,\n",
       "          671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683,\n",
       "          684, 685, 686, 687]),\n",
       "   array([138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
       "          151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "          164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
       "          177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
       "          190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
       "          203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
       "          216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "          229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "          242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
       "          255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
       "          268, 269, 270, 271, 272, 273, 274, 275]))),\n",
       " (3, (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "           13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "           26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "           39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "           52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "           65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "           78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "           91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "          104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "          117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "          130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "          143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "          156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "          169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "          182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "          195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "          208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "          221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "          234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "          247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "          260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "          273, 274, 275, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
       "          424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
       "          437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
       "          450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "          463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "          476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
       "          489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
       "          502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514,\n",
       "          515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527,\n",
       "          528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540,\n",
       "          541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
       "          554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566,\n",
       "          567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579,\n",
       "          580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592,\n",
       "          593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605,\n",
       "          606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618,\n",
       "          619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631,\n",
       "          632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644,\n",
       "          645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
       "          658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670,\n",
       "          671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683,\n",
       "          684, 685, 686, 687]),\n",
       "   array([276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
       "          289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
       "          302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n",
       "          315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327,\n",
       "          328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
       "          341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
       "          354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366,\n",
       "          367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "          380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "          393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "          406, 407, 408, 409, 410, 411, 412, 413]))),\n",
       " (4, (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "           13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "           26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "           39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "           52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "           65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "           78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "           91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "          104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "          117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "          130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "          143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "          156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "          169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "          182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "          195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "          208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "          221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "          234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "          247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "          260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "          273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "          286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "          299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "          312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "          325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "          338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "          351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "          364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "          377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "          390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "          403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 551, 552,\n",
       "          553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
       "          566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
       "          579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591,\n",
       "          592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
       "          605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617,\n",
       "          618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
       "          631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
       "          644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656,\n",
       "          657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669,\n",
       "          670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682,\n",
       "          683, 684, 685, 686, 687]),\n",
       "   array([414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "          427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "          440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "          453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "          466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "          479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "          492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
       "          505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
       "          518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530,\n",
       "          531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543,\n",
       "          544, 545, 546, 547, 548, 549, 550]))),\n",
       " (5, (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "           13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "           26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "           39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "           52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "           65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "           78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "           91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "          104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "          117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "          130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "          143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "          156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "          169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "          182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "          195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "          208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "          221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "          234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "          247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "          260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "          273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "          286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "          299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "          312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "          325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "          338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "          351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "          364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "          377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "          390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "          403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "          416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "          429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "          442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "          455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "          468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "          481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "          494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "          507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "          520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "          533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "          546, 547, 548, 549, 550]),\n",
       "   array([551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "          564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
       "          577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
       "          590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
       "          603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
       "          616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628,\n",
       "          629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641,\n",
       "          642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654,\n",
       "          655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
       "          668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680,\n",
       "          681, 682, 683, 684, 685, 686, 687])))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the values.ravel() function takes a column and turns it into an array... \n",
    "\n",
    "y_train_undersample.iloc[fold_list[0][1][0],:].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is a function to make a confusion matrix plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Despite putting this 'if normalize' conditionial statement\n",
    "    # it never got used. But if he ever did call it though, it but it does\n",
    "    # normalize the data if he set normal = true in the arguments of the\n",
    "    # function I when called.\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    \n",
    "    # This part just writes the amounts inside each box, changing the text color for\n",
    "    # each box depending on the threshold\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is with the train set data... recall score is 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall metric in the testing dataset:  0.938775510204\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7Mc/h8qVUEpbY378wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d697fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use this C_parameter to build the final model with the whole training dataset and predict the classes in the test\n",
    "# dataset\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74635 10661]\n",
      " [   11   136]] \n",
      "\n",
      "[[  7.46e+04   1.07e+04]\n",
      " [  1.10e+01   1.36e+02]] \n",
      "\n",
      "[74646 10797] \n",
      "\n",
      "[85296   147] \n",
      "\n",
      "[[85296]\n",
      " [  147]] \n",
      "\n",
      "[[ 0.88  0.12]\n",
      " [ 0.07  0.93]] \n",
      "\n",
      "74635 \n",
      "\n",
      "(2, 2)\n",
      "range(0, 2)\n",
      "[(0, 0), (0, 1), (1, 0), (1, 1)]\n",
      "[(0, 0), (0, 1), (0, 1), (1, 0), (1, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "# I just want to see what this np.newaxis thing does...\n",
    "\n",
    "# Here is the confusion matrix\n",
    "print(cnf_matrix, '\\n')\n",
    "\n",
    "# Here it changed the ints into floats\n",
    "print(cnf_matrix.astype('float'), '\\n') \n",
    "\n",
    "# This added the columns together \n",
    "print(cnf_matrix.sum(axis= 0), '\\n')\n",
    "\n",
    "# This added the rows together\n",
    "print(cnf_matrix.sum(axis= 1), '\\n')\n",
    "\n",
    "# This took the added up rows and turned it into a one column scalar to be used \n",
    "# for whatever mathmatical operation you want with a DF with similar dimensions.\n",
    "print(cnf_matrix.sum(axis=1)[:, np.newaxis], '\\n')\n",
    "\n",
    "\n",
    "# Used the new axis to divide the matrix that had the floats in it...\n",
    "print(cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis], '\\n')\n",
    "\n",
    "# This gets the biggest value in the confusion matrix\n",
    "print(cnf_matrix.max(), '\\n')\n",
    "\n",
    "print(cnf_matrix.shape)\n",
    "print(range(cnf_matrix.shape[0]))\n",
    "\n",
    "# intertools.product sort of works like FOIL... creating an array of tuples  \n",
    "# that can be used in a loop\n",
    "print(list(itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1]))))\n",
    "\n",
    "print(list(itertools.product( (0,1), (0,1,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is with the test data... score is 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall metric in the testing dataset:  0.925170068027\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8V1W9//HX+4AoDkwiqOCUIqhcB0DEUjNNQDRRf2Uq\nKppJ5XAtGy6WXRxvVrdB0iy6klAm0kCSokSUpSbKIII4gZoBIoMIDpiKfn5/7HXwK53he+Bs9jnf\n83762I/v3muvvff6cuTDOp+99tqKCMzMLB9VRTfAzKySOciameXIQdbMLEcOsmZmOXKQNTPLkYOs\nmVmOHGRbGEltJf1B0lpJv96M8wyT9MfGbFtRJB0p6emi22GVSR4n2zRJOhO4DOgFvAbMBa6LiAc2\n87xnA5cAH46I9Zvd0CZOUgA9ImJR0W2xlsk92SZI0mXAD4H/AboCuwM/BoY2wun3AJ5pCQG2HJJa\nF90Gq3AR4aUJLUB74HXgU3XU2ZosCL+Ylh8CW6d9RwNLgC8DK4BlwHlp31XA28A76RrnA1cCvyw5\n955AAK3T9rnAc2S96eeBYSXlD5Qc92FgJrA2fX64ZN99wDXAg+k8fwQ61/Ldqtv/tZL2nwwMAZ4B\nVgNfL6nfH3gIWJPq3gi0Sfv+lr7LG+n7frrk/P8FvAT8orosHbN3ukaftL0rsBI4uuj/N7w0z8U9\n2abncGAbYFIddb4BDAAOBg4iCzRXlOzfmSxYdyMLpDdJ6hgRo8h6x3dExPYRcUtdDZG0HTAaOD4i\ndiALpHNrqNcJuDvV3RH4PnC3pB1Lqp0JnAd0AdoAX6nj0juT/Rl0A/4b+BlwFtAXOBL4pqS9Ut13\ngS8Bncn+7I4FLgSIiKNSnYPS972j5PydyHr1I0ovHBHPkgXgX0raFvg5MC4i7qujvWa1cpBtenYE\nVkXdv84PA66OiBURsZKsh3p2yf530v53ImIKWS+u5ya25z2gt6S2EbEsIhbUUOcEYGFE/CIi1kfE\n7cBTwCdK6vw8Ip6JiDeBiWT/QNTmHbL88zvABLIAekNEvJau/wTZPy5ExOyImJGu+w/gp8BHy/hO\noyLirdSeD4iInwGLgIeBXcj+UTPbJA6yTc/LQOd6coW7Ai+UbL+QyjacY6MgvQ7YvqENiYg3yH7F\n/jywTNLdknqV0Z7qNnUr2X6pAe15OSLeTevVQXB5yf43q4+XtK+kuyS9JOlVsp565zrODbAyIv5V\nT52fAb2BH0XEW/XUNauVg2zT8xDwFlkesjYvkv2qW233VLYp3gC2LdneuXRnREyNiOPIenRPkQWf\n+tpT3aalm9imhriZrF09IqId8HVA9RxT55AaSduT5blvAa5M6RCzTeIg28RExFqyPORNkk6WtK2k\nrSQdL+k7qdrtwBWSdpLUOdX/5SZeci5wlKTdJbUHLq/eIamrpKEpN/sWWdrhvRrOMQXYV9KZklpL\n+jSwP3DXJrapIXYAXgVeT73sL2y0fznwoQae8wZgVkR8lizX/JPNbqW1WA6yTVBEfI9sjOwVZHe2\nFwMXA79PVa4FZgHzgPnAnFS2KdeaBtyRzjWbDwbGqtSOF8nuuH+Ufw9iRMTLwIlkIxpeJhsZcGJE\nrNqUNjXQV8huqr1G1su+Y6P9VwLjJK2RdFp9J5M0FBjM+9/zMqCPpGGN1mJrUfwwgplZjtyTNTPL\nkYOsmVmOHGTNzHLkIGtmlqMmNTmGWrcNtdmh6GZYIzqgR/eim2CNaOmSf7L65VX1jUMuW6t2e0Ss\n/7eH7moVb66cGhGDG+v6W0LTCrJtdmDrnvWOsrFm5Hf3fqf+StZsnDrwiEY9X6x/s0F/5/8196b6\nnuZrcppUkDWzlkagys5aOsiaWXEEqNGyD02Sg6yZFcs9WTOzvAiqWhXdiFw5yJpZsZwuMDPLiXC6\nwMwsP3JP1swsV+7JmpnlyD1ZM7O8VP7DCJX97cysaat+GKHcpb7TST0lzS1ZXpX0RUmdJE2TtDB9\ndkz1JWm0pEWS5knqU3Ku4an+QknDS8r7Spqfjhkt1d0wB1kzK5aqyl/qERFPR8TBEXEw0JfszciT\ngJHA9IjoAUxP2wDHAz3SMoLsxZykl2eOAg4D+gOjqgNzqnNByXF1TljjIGtmBVKjBtmNHAs8GxEv\nAEOBcal8HO+/DXooMD4yM4AOknYBBgHTImJ1RLwCTAMGp33tImJGZO/uGk/db5Z2TtbMCiSgVYOe\n+OosaVbJ9piIGFNL3dPJ3uwM0DUilqX1l4Cuab0b2YtKqy1JZXWVL6mhvFYOsmZWrIaNLlgVEf3q\nP6XaACdR8or7ahERkrbYG2SdLjCzAuWWLjgemBMRy9P28vSrPulzRSpfCuxWclz3VFZXefcaymvl\nIGtmxWrE0QUlzuD9VAHAZKB6hMBw4M6S8nPSKIMBwNqUVpgKDJTUMd3wGghMTftelTQgjSo4p+Rc\nNXK6wMyK1cjjZCVtBxwHfK6k+HpgoqTzgReA6tcxTAGGAIvIRiKcBxARqyVdA8xM9a6OiNVp/ULg\nVqAtcE9aauUga2bFaXgPtV4R8Qaw40ZlL5ONNti4bgAX1XKescDYGspnAb3LbY+DrJkVq8Kf+HKQ\nNbNiee4CM7O8VP7cBQ6yZlYs92TNzHLiNyOYmeXJL1I0M8uXe7JmZjlyTtbMLCfy6AIzs3y5J2tm\nlp963t7S7DnImllhsld8OciameVDaalgDrJmViC5J2tmlicHWTOzHFVVeQiXmVk+nJM1M8uPnJM1\nM8uXg6yZWY4cZM3McuQga2aWlxZw46uyx06YWZMnqeylzPN1kPQbSU9JelLS4ZI6SZomaWH67Jjq\nStJoSYskzZPUp+Q8w1P9hZKGl5T3lTQ/HTNa9TTMQdbMClM9uqAxgyxwA3BvRPQCDgKeBEYC0yOi\nBzA9bQMcD/RIywjgZgBJnYBRwGFAf2BUdWBOdS4oOW5wXY1xkDWzQjVmkJXUHjgKuAUgIt6OiDXA\nUGBcqjYOODmtDwXGR2YG0EHSLsAgYFpErI6IV4BpwOC0r11EzIiIAMaXnKtGzsmaWXEEqmpQUraz\npFkl22MiYkzJ9l7ASuDnkg4CZgOXAl0jYlmq8xLQNa13AxaXHL8kldVVvqSG8lo5yJpZoRo4umBV\nRPSrY39roA9wSUQ8LOkG3k8NABARISka3tJN43SBmRWqkXOyS4AlEfFw2v4NWdBdnn7VJ32uSPuX\nAruVHN89ldVV3r2G8lo5yJpZYRr7xldEvAQsltQzFR0LPAFMBqpHCAwH7kzrk4Fz0iiDAcDalFaY\nCgyU1DHd8BoITE37XpU0II0qOKfkXDVyusDMitX442QvAW6T1AZ4DjiPrEM5UdL5wAvAaanuFGAI\nsAhYl+oSEaslXQPMTPWujojVaf1C4FagLXBPWmrlIGtmxVHjP/EVEXOBmvK2x9ZQN4CLajnPWGBs\nDeWzgN7ltsfpgk3UY48uzJgwcsOy/P7vcvGZR2/Yf+nZx/DmozeyY4ftNpQd2bcHMyaMZPZvvsEf\n/+9SALZu05r7f/EVHr4jK7/i80M21B9z1Vk8edeVG65x4L513sS0zXT5Fz/PgAP24ISPvv/3c80r\nqzn3tBM57vADOfe0E1m75pUN+x5+8G+cdOwAhhzVj2EnD9pQ/uraNVxy/jAGHXEIg4/sw6OzsvTg\nPZN/x5Cj+tFzl+2ZP3fOlvtiTVwO42SbFPdkN9HCF1Yw4PTrAaiqEs9OvY7Jf3kMgO5dO3DsgP34\n57LVG+q3374tN3z9NIZe9GMWv/QKO3XcHoC33l7P4BGjeePNt2nduoo/j72MPz74BI/M/wcAX//h\n75n0p7lb9su1UKd++izO+szn+NolF2woG/Oj73H4kUfzuUu+wk9/9L+M+dH3+Oo3r+XVtWu4cuSX\nuOX237Nr9914eeWKDcdce8VXOfKY4/jRLbfx9ttv86831wHQo9f+3Dj2V/z3V/9zi3+3pqy5Bs9y\nuSfbCD7WvyfPL1nJP5dlvZzvfOX/8Y0bfk/2m0jm08f3487pj7H4pazOylde37DvjTffBmCr1q1o\n3brVB46zLefQw4+gfYdOHyibPvVuTjltGACnnDaMP917FwB/+N1EBp5wErt2z25A77hTFwBee3Ut\ns2Y8yKfOzO6xtGnThnbtOwCwz769+NA++26R79KsqAFLM+Qg2wg+NagvE++dDcCJR/8HL65Yw/xn\nPjiqo8ceXejQblum/uxSHrzta5x5Yv8N+6qqxIwJI/nn9Ov584ynmPn4Cxv2XXnRJ3jkjsv5zpdP\npc1W/sVjS1u1cgVduu4CwE5ddmZV6rH+47mFrF2zhrNOGcwpAz/CpIm3AbD4n/+g446dGXnp5xj6\n8cP5+mUXsu6NNwprf3NQ6emCXIOspMGSnk4TKYys/4jmZ6vWrTjho//B76Y9SttttuJrnxnE1Tff\n/W/1Wreqos9+u3HKJTdz0kU3cfkFg9ln96z38957wYDTr2efQVfQr/ce7L939pf6v380mYNOuYYj\nzvouHdtvx5fP+/gW/W72QaV/0devf5cF8x5lzC9/yy2338mPf/Btnn92Ie+uf5cn5s/lzHMv4M4/\nPcS2227LmBu/V3DLm66GBFgH2Y1IagXcRDYBw/7AGZL2z+t6RRl0xP7MfWoxK1a/xoe678Qe3Xbk\nkTsu56m7r6Jblw489Kv/ouuOO7B0xRqmPfQk6/71Ni+veYMH5iz6txtZa19/k7/OeoaBH87+mF5a\n9SoAb7+znvF3zqDfAXtu6a/X4nXeqQsrlmdPY65YvowdO+8EwM677soRR3+cbbfbjk47dubQAR/h\nqQXz2XnXXdl5l24c1OdQAAadeAoL5jmnXpeqqqqyl+Yoz1b3BxZFxHMR8TYwgWwyhopy2uB+G1IF\nCxa9yB7HXk6vE0bR64RRLF2xhsPP/DbLX36NP9w3jw8fvDetWlXRdputOLT3njz1/Et07rg97bdv\nC8A2W2/FsYf14ul/LAdg587tNlznpI8dyBPPvrjlv2ALd8zAIRtSAZMm3saxg04A4NhBJzL7kb+z\nfv163ly3jsfmzGTvHj3ZqcvO7NytO88tegaAh+6/j3327VVY+5uFCs/J5pnkq2mChcM2riRpBNkU\nY7DV9jk2p/Ftu00bjjmsFxdfe3u9dZ9+fjnT/v4EMydeznvvBbdO+jtPPLuM3j125WdXn02rqiqq\nqsRvp83hnvsfB+Dn1w2nc8cdkGDe00u45LoJeX+lFu1Lnx/OI3+/n1dWv8yRh/TgP796BSMu+TKX\njjib3/xqPLt2340bxvwCyG5iHfWx4/jExw6jqkp8ati57LvfAQB887r/5SsXfoZ33nmb7nvsxfU/\n/AkAf5wymWu+8WVWv7yKEWedyn69D2TshMmFfd+mormmAcqlvO5kS/okMDgiPpu2zwYOi4iLazum\natsusXXP02rbbc3QvHu/U3QTrBGdOvAI5j82p9Gi4tY794juw0aXXf+57w+ZXc8EMU1Onj3Z2iZY\nMDMDUhagsjuyueZkZwI9JO2VniE+nWwyBjOzpPJHF+TWk42I9ZIuJpvNphUwNiIW5HU9M2uemmns\nLFuuo9sjYgrZLDdmZjVqrj3UcvkRIjMrjtyTNTPLjcgeK69kDrJmVigHWTOzvDhdYGaWn2ycbGVH\nWQdZMytQ8x3/Wi4HWTMrVIXHWAdZMyuWe7JmZnlpATe+mucsuGZWEapvfDXm3AWS/iFpvqS5kmal\nsk6SpklamD47pnJJGp3e3jJPUp+S8wxP9RdKGl5S3jedf1E6ts6GOciaWaGk8pcG+FhEHFwyLeJI\nYHpE9ACmp23I3tzSIy0jgJuzNqkTMIpsDuz+wKjqwJzqXFBy3OC6GuIga2aF2kKzcA0FxqX1ccDJ\nJeXjIzMD6CBpF2AQMC0iVkfEK8A0YHDa1y4iZkQ2Gff4knPVyDlZMyuOGvzEV+fqFEAyJiLGbFQn\ngD9KCuCnaX/XiFiW9r8EdE3rNb3BpVs95UtqKK+Vg6yZFWYTJu1eVcabEY6IiKWSugDTJD1VujMi\nIgXgLcLpAjMrUONP2h0RS9PnCmASWU51efpVn/S5IlWv7Q0udZV3r6G8Vg6yZlaoxrzxJWk7STtU\nrwMDgcfJ3spSPUJgOHBnWp8MnJNGGQwA1qa0wlRgoKSO6YbXQGBq2veqpAFpVME5JeeqkdMFZlao\nRn4YoSswKZ2zNfCriLhX0kxgoqTzgReA6je2TgGGAIuAdcB5ABGxWtI1ZK/RArg6Ilan9QuBW4G2\nwD1pqZWDrJkVp5EfRoiI54CDaih/GTi2hvIALqrlXGOBsTWUzwJ6l9smB1kzK4xn4TIzy5mDrJlZ\njio8xjrImlmx3JM1M8tLC5iFy0HWzAoj5BcpmpnlqarCu7IOsmZWqAqPsQ6yZlac7HHZyo6yDrJm\nVqgKT8k6yJpZsVpsT1ZSu7oOjIhXG785ZtbSVHiMrbMnu4BshvHSP4Lq7QB2z7FdZtYCiGwYVyWr\nNchGxG617TMzayyVnpMta9JuSadL+npa7y6pb77NMrMWoQFvRWiuudt6g6ykG4GPAWenonXAT/Js\nlJm1DAJaVanspTkqZ3TBhyOij6RHYcOM4W1ybpeZtRDNtINatnKC7DuSqshudiFpR+C9XFtlZi1G\nc00DlKucnOxNwG+BnSRdBTwAfDvXVplZi9CQlyg211hcb082IsZLmg18PBV9KiIez7dZZtZSeIKY\nTCvgHbKUgV8jbmaNprJDbHmjC74B3A7sCnQHfiXp8rwbZmYtQ6UP4SqnJ3sOcEhErAOQdB3wKPCt\nPBtmZpVP+GEEgGV8MBi3TmVmZpsnp4cRJLWS9Kiku9L2XpIelrRI0h3Vw1AlbZ22F6X9e5ac4/JU\n/rSkQSXlg1PZIkkj62tLrUFW0g8kfR9YDSyQ9H+SfgbMB1aV/W3NzOqQ0+iCS4EnS7a/DfwgIvYB\nXgHOT+XnA6+k8h+kekjaHzgdOAAYDPw4Be5WZCOujgf2B85IdWtVV7qgegTBAuDukvIZ9X49M7My\nVD/x1ajnlLoDJwDXAZcp6wIfA5yZqowDrgRuBoamdYDfADem+kOBCRHxFvC8pEVA/1RvUUQ8l641\nIdV9orb21DVBzC2b8P3MzBqkgTe0OkuaVbI9JiLGbFTnh8DXgB3S9o7AmohYn7aXAN3SejdgMUBE\nrJe0NtXvxgc7lKXHLN6o/LC6GlzvjS9Je5P9i7A/sE11eUTsW9+xZmb1aWA/dlVE9Kv1XNKJwIqI\nmC3p6M1rWeMoZ3TBrcC1wP+S5SHOIz1ia2a2OaRGfxjhI8BJkoaQdQrbATcAHSS1Tr3Z7sDSVH8p\nsBuwRFJroD3wckl5tdJjaiuvUTmjC7aNiKkAEfFsRFxBFmzNzDZbY974iojLI6J7ROxJduPqzxEx\nDPgL8MlUbThwZ1qfnLZJ+/8cEZHKT0+jD/YCegCPADOBHmm0Qpt0jcl1tamcnuxbaYKYZyV9nixq\n71DPMWZmZdlCDxn8FzBB0rVk4/yr7zndAvwi3dhaTRY0iYgFkiaS3dBaD1wUEe+m9l4MTCV7EnZs\nRCyo68LlBNkvAdsB/0mWm20PfKZBX8/MrBZ5xdiIuA+4L60/x/ujA0rr/Av4VC3HX0cW8zYunwJM\nKbcd5UwQ83BafY33J+42M9tsQi13ghhJk6jjBldEnJpLi8ys5WjGUxiWq66e7I1brBXJIfvtzoMP\nb/HLmlmZ2rRu/En4muvEL+Wq62GE6VuyIWbWMlX63KnlzidrZtbo8nistqlxkDWzQlV4jC0/yEra\nOk2WYGbWKLKHDCo7ypbzZoT+kuYDC9P2QZJ+lHvLzKxFqFL5S3NUTs55NHAi2fO8RMRjwMfybJSZ\ntRwt/m21QFVEvLBRl/7dnNpjZi1I9vqZZho9y1ROkF0sqT8QaVbwS4Bn8m2WmbUUHsIFXyBLGewO\nLAf+lMrMzDZbhXdky5q7YAVpZhozs8YkteC5C6qllyf+2xwGETEilxaZWYtS4TG2rHTBn0rWtwFO\n4YPvuDEz2yQCWjfXsVllKiddcEfptqRfAA/k1iIza1Hck/13ewFdG7shZtYCNeOHDMpVTk72Fd7P\nyVaRvaJhZJ6NMrOWQw19X20zU2eQVfYEwkG8/zbG99JLxszMNlv2MELRrchXneOAU0CdEhHvpsUB\n1swalecugLmSDsm9JWbWIkkqe2mO6nrHV+uIWA8cAsyU9CzwBlkPPyKizxZqo5lVqJaeLngkfZ4E\n9ASGkL0695PU8gpdM7MGacAMXOV0ZCVtI+kRSY9JWiDpqlS+l6SHJS2SdIekNql867S9KO3fs+Rc\nl6fypyUNKikfnMoWSap3EEBdN74EEBHP1v/VzMw2TSM/VvsWcExEvC5pK+ABSfcAlwE/iIgJkn4C\nnA/cnD5fiYh9JJ0OfBv4tKT9yaYTOADYFfiTpH3TNW4CjgOWkP2WPzkinqitQXUF2Z0kXVbbzoj4\nfplf2sysRtk7vhrvfOnm/Otpc6u0BHAMcGYqHwdcSRZkh6Z1gN8AN6ZRVUOBCeltMM9LWgT0T/UW\nRcRzAJImpLqbFGRbAdtDhQ9iM7MCiaqGhZjOkmaVbI+JiDEfOGM2JetsYB+yXuezwJp0jwmyHmi3\ntN6NNE1ARKyXtBbYMZXPKDlt6TGLNyo/rK4G1xVkl0XE1XUdbGa2OUSDH6tdFRH96qoQEe8CB0vq\nAEwCem1yAxtBvTlZM7Pc5Dj+NSLWSPoLcDjQoWTEVHfef8BqKbAbsERSa6A92au2qsurlR5TW3mN\n6sqGHFvmdzEz22RVaU7Zcpb6SNop9WCR1JbsBtWTwF/IRkYBDAfuTOuT0zZp/59TXncycHoafbAX\n0INsxNVMoEcardCG7ObY5LraVGtPNiJW1/uNzMw2wyakC+qzCzAu5WWrgIkRcZekJ4AJkq4FHgVu\nSfVvAX6RbmytJr2gICIWSJpIdkNrPXBRSkMg6WJgKtl9q7ERsaCuBm3KLFxmZo2mMYdwRcQ8sgeo\nNi5/jvdHB5SW/4taxv1HxHXAdTWUTwGmlNsmB1kzK1QzfVq2bA6yZlYY4bfVmpnlRzTbiV/K5SBr\nZoWq7BDrIGtmBRLQyj1ZM7P8VHiMdZA1syI138m4y+Uga2aF8egCM7OcuSdrZpajyg6xDrJmViSP\nkzUzy49zsmZmOXNP1swsR5UdYh1kzaxAfuLLzCxnFR5jHWTNrEhCFZ4wcJA1s0K5J2tmlpNsCFdl\nR1kHWTMrjtyTNTPLlYOsmVmOKv3GV6U/0Va4z332M+y+axf6Htx7Q9lvf/Nr+hx0ANu2qWL2rFkF\nts7KUdPP8KpR3+TQQw7ksL4Hc+LxA3nxxRc37PvbX+/jsL4H0+egAzjumI8W0eRmQ0CVyl/qPZ+0\nm6S/SHpC0gJJl6byTpKmSVqYPjumckkaLWmRpHmS+pSca3iqv1DS8JLyvpLmp2NGq55H1hxkc3b2\n8HO58657P1B2wAG9mTDxdxxx5FEFtcoaoqaf4Ze+/FVmPjqPh2fP5fghJ/Kta68GYM2aNVx6yYX8\netJk5jy2gNsm/LqIJjcrasB/ZVgPfDki9gcGABdJ2h8YCUyPiB7A9LQNcDzQIy0jgJshC8rAKOAw\noD8wqjowpzoXlBw3uK4GOcjm7Igjj6JTp04fKOu1337s27NnQS2yhqrpZ9iuXbsN6+vWvbHh+fs7\nbv8VQ08+ld133x2ALl26bLmGNlNVUtlLfSJiWUTMSeuvAU8C3YChwLhUbRxwclofCoyPzAygg6Rd\ngEHAtIhYHRGvANOAwWlfu4iYEREBjC85V42ckzXbRKO++Q1u++V42rdvz73T/gLAwoXPsP6ddxh4\n7NG8/tprXHTJpQw7+5yCW9p0VacLGqCzpNIc25iIGFPjuaU9gUOAh4GuEbEs7XoJ6JrWuwGLSw5b\nksrqKl9SQ3mtcuvJShoraYWkx/O6hlmRrrrmOhY9v5jTzxjGT358IwDr169nzpzZTJp8N5OnTOVb\n/3MNC595puCWNmUNSRYIYFVE9CtZaguw2wO/Bb4YEa+W7ks90Mj9qyV5pgtupZ5chVkl+PQZw/j9\npN8C0K17d44bOIjtttuOzp07c8QRRzFv3mMFt7AJS+Nky13KOqW0FVmAvS0ifpeKl6df9UmfK1L5\nUmC3ksO7p7K6yrvXUF6r3IJsRPwNWJ3X+c2KtGjhwg3rd02+k3179gLgE58Yyt8ffID169ezbt06\nZs58mF699iuqmc2CGrDUe64sOX4L8GREfL9k12SgeoTAcODOkvJz0iiDAcDalFaYCgyU1DHd8BoI\nTE37XpU0IF3rnJJz1ajwnKykEWR39dgt3SyoJOecdQb3//U+Vq1axd57dueb/30VHTt14rIvXsKq\nlSs5degJHHjQwfxhytSim2q1qOlneO+9U1j4zNNUqYrd99iD0Tf9BMhuah43aDCH9jmQqqoqzj3v\nsxzQu3c9V2i5spxso46T/QhwNjBf0txU9nXgemCipPOBF4DT0r4pwBBgEbAOOA8gIlZLugaYmepd\nHRHVncYLyX5Tbwvck5ZaKUtP5CMlnu+KiLL+L+vbt188+LDHjZo1VR85rB+zZ89qtKi4338cEj+f\n9Jey6x/eo+PsiOjXWNffEgrvyZpZC1fZD3w5yJpZsfxY7SaSdDvwENBT0pKUCzEz+4DGHl3Q1OTW\nk42IM/I6t5lVjmYaO8vmdIGZFUb4leBmZvlpxmmAcjnImlmhKjzGOsiaWcEqPMo6yJpZgfxKcDOz\nXDkna2aWk3InfmnOHGTNrFgVHmUdZM2sUM7JmpnlyDlZM7O8+GEEM7N8OV1gZpaTbO6ColuRLwdZ\nMytUhcdYB1kzK1iFR1kHWTMrlHOyZmY5ck7WzCxHFR5j83vHl5lZWdSApb5TSWMlrZD0eElZJ0nT\nJC1Mnx1TuSSNlrRI0jxJfUqOGZ7qL5Q0vKS8r6T56ZjRKuO1Dg6yZlaYLHaW/18ZbgUGb1Q2Epge\nET2A6Wkb4HigR1pGADdDFpSBUcBhQH9gVHVgTnUuKDlu42v9GwdZMyuOoKoBS30i4m/A6o2KhwLj\n0vo44OTb5/aHAAAGQUlEQVSS8vGRmQF0kLQLMAiYFhGrI+IVYBowOO1rFxEzIiKA8SXnqpVzsmZW\nrPyTsl0jYllafwnomta7AYtL6i1JZXWVL6mhvE4OsmZWoAa/GaGzpFkl22MiYky5B0dESIqGXHBz\nOciaWaEaOIRrVUT0a+AllkvaJSKWpV/5V6TypcBuJfW6p7KlwNEbld+XyrvXUL9OzsmaWWEaMrBg\nM7IKk4HqEQLDgTtLys9JowwGAGtTWmEqMFBSx3TDayAwNe17VdKANKrgnJJz1co9WTMrViPmZCXd\nTtYL7SxpCdkogeuBiZLOB14ATkvVpwBDgEXAOuA8gIhYLekaYGaqd3VEVN9Mu5BsBENb4J601MlB\n1swK1ZiP1UbEGbXsOraGugFcVMt5xgJjayifBfRuSJscZM2sUH6s1swsRxUeYx1kzaxAfv2MmVne\nKjvKOsiaWWFEeY/LNmcOsmZWKKcLzMxy5DcjmJnlqbJjrIOsmRWrwmOsg6yZFUcewmVmli/nZM3M\n8lTZMdZB1syKVeEx1kHWzIrlnKyZWU6EqKrwKOs3I5iZ5cg9WTMrVIV3ZB1kzaxYHsJlZpYXP4xg\nZpafzXwLbbPgIGtmxarwKOsga2aFck7WzCxHzsmameWowmOsg6yZFUsV3pV1kDWzwojKTxcoIopu\nwwaSVgIvFN2OLaAzsKroRlijaik/0z0iYqfGOpmke8n+7Mq1KiIGN9b1t4QmFWRbCkmzIqJf0e2w\nxuOfqdXGE8SYmeXIQdbMLEcOssUYU3QDrNH5Z2o1ck7WzCxH7smameXIQdbMLEcOsluQpMGSnpa0\nSNLIottjm0/SWEkrJD1edFusaXKQ3UIktQJuAo4H9gfOkLR/sa2yRnAr0KwGx9uW5SC75fQHFkXE\ncxHxNjABGFpwm2wzRcTfgNVFt8OaLgfZLacbsLhke0kqM7MK5iBrZpYjB9ktZymwW8l291RmZhXM\nQXbLmQn0kLSXpDbA6cDkgttkZjlzkN1CImI9cDEwFXgSmBgRC4ptlW0uSbcDDwE9JS2RdH7RbbKm\nxY/VmpnlyD1ZM7McOciameXIQdbMLEcOsmZmOXKQNTPLkYNsBZH0rqS5kh6X9GtJ227GuY6WdFda\nP6muWcMkdZB04SZc40pJXym3fKM6t0r6ZAOutadnyrIiOMhWljcj4uCI6A28DXy+dKcyDf6ZR8Tk\niLi+jiodgAYHWbOWwEG2ct0P7JN6cE9LGg88DuwmaaCkhyTNST3e7WHDfLdPSZoDnFp9IknnSrox\nrXeVNEnSY2n5MHA9sHfqRX831fuqpJmS5km6quRc35D0jKQHgJ71fQlJF6TzPCbptxv1zj8uaVY6\n34mpfitJ3y259uc29w/SbHM4yFYgSa3J5q2dn4p6AD+OiAOAN4ArgI9HRB9gFnCZpG2AnwGfAPoC\nO9dy+tHAXyPiIKAPsAAYCTybetFflTQwXbM/cDDQV9JRkvqSPU58MDAEOLSMr/O7iDg0Xe9JoPSJ\nqj3TNU4AfpK+w/nA2og4NJ3/Akl7lXEds1y0LroB1qjaSpqb1u8HbgF2BV6IiBmpfADZpOEPSgJo\nQ/ZYaC/g+YhYCCDpl8CIGq5xDHAOQES8C6yV1HGjOgPT8mja3p4s6O4ATIqIdeka5czd0FvStWQp\nie3JHkuuNjEi3gMWSnoufYeBwIEl+dr26drPlHEts0bnIFtZ3oyIg0sLUiB9o7QImBYRZ2xU7wPH\nbSYB34qIn250jS9uwrluBU6OiMcknQscXbJv42fCI137kogoDcZI2nMTrm222ZwuaHlmAB+RtA+A\npO0k7Qs8Bewpae9U74xajp8OfCEd20pSe+A1sl5qtanAZ0pyvd0kdQH+Bpwsqa2kHchSE/XZAVgm\naStg2Eb7PiWpKrX5Q8DT6dpfSPWRtK+k7cq4jlku3JNtYSJiZeoR3i5p61R8RUQ8I2kEcLekdWTp\nhh1qOMWlwJg029S7wBci4iFJD6YhUvekvOx+wEOpJ/06cFZEzJF0B/AYsIJs+sf6fBN4GFiZPkvb\n9E/gEaAd8PmI+Jek/yPL1c5RdvGVwMnl/emYNT7PwmVmliOnC8zMcuQga2aWIwdZM7McOciameXI\nQdbMLEcOsmZmOXKQNTPL0f8HjOT4IYU/v1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d6a5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use this C_parameter to build the final model with the whole training dataset and predict the classes in the test\n",
    "# dataset\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred = lr.predict(X_test.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still pretty new to this one... not sure what's going on exactly... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUqJQkREklKiEBGRpP4f45NaoeQKyVIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e8994e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC CURVE\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "y_pred_undersample_score = lr.fit(X_train_undersample,y_train_undersample.values.ravel()).decision_function(X_test_undersample.values)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_undersample.values.ravel(),y_pred_undersample_score)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15 -0.23  6.5  -0.31 -0.84  4.51  1.66 -0.39 -0.43  0.29  0.57 -0.4\n",
      "  7.09  5.31  0.3   3.91  0.16 -0.35  3.18  6.92  0.47  0.19  7.04 -0.49\n",
      "  3.59 -0.9   2.77  1.11 -0.48 -0.49  0.94 -0.22  1.04 -0.08  3.7   3.28\n",
      "  6.4  -0.54  2.25  3.18  6.48  0.24 -0.53  7.31 -0.4  -0.44  2.62  2.3\n",
      "  3.57 -0.43 -0.12  0.94 -0.52 -0.33  1.61  3.69 -0.48 -0.48  1.42  3.39\n",
      "  3.2  -0.47  2.49 -0.47 -0.54 -0.56  3.89 -0.47 -0.42 -0.35 -0.68 -0.53\n",
      "  0.19  0.11 -0.28  5.77 -0.57  1.43  3.32 -0.45  1.88 -0.29  0.91  2.31\n",
      " -0.02 -0.43  4.14 -0.17  4.87 -0.25 -0.3  -0.62 -0.38 -0.05  4.34 -0.14\n",
      "  3.36 -0.59  2.02 -0.04  3.37  0.66 -0.51 -0.06  1.9  -0.45 -0.37  6.18\n",
      " -0.67  1.97  0.04  4.38  4.59  1.14 -0.58 -0.19  2.42 -0.19 -0.93  4.55\n",
      "  3.87 -0.57 -0.59  3.59  1.75 -0.26 -0.56 -0.56 -0.97 -0.27  1.55 -0.13\n",
      "  5.38  6.48  6.23  4.4   3.65 -0.17 -0.41  2.09 -0.31 -0.24 -0.53 -0.31\n",
      " -0.5   3.18 -0.3  -0.34  0.26  2.12  4.55 -0.6   0.49 -0.18  0.03  1.35\n",
      " -0.15 -0.46 -0.28 -0.51 -0.08  1.62  4.54 -0.35  2.46  4.55  6.54  3.81\n",
      " -0.4  -0.41  2.89 -0.42 -0.58  1.95 -0.25  4.57 -0.4  -0.29 -0.37 -0.3\n",
      " -0.33  1.85 -0.1   2.63 -0.18  1.8  -0.38  5.57  0.45 -0.83  0.25 -0.57\n",
      "  6.68 -0.28  7.87 -0.53 -0.48 -0.38  1.77  1.49  0.13 -0.23 -0.43  1.86\n",
      "  1.62  1.81  0.69 -0.17  3.08  0.38 -0.4  -0.55  4.99  3.26  4.38  3.12\n",
      " -0.34  2.27  4.1   5.76  0.07  1.69  1.47 -0.38 -0.08  6.39  0.72  4.2\n",
      "  2.88 -0.15 -0.42  0.12 -0.23  1.24 -0.55 -0.34 -0.21  0.39  1.51  3.96\n",
      "  0.37 -0.54 -0.41 -0.31 -0.11 -0.57  0.05  3.54  2.98 -0.48 -0.4   4.15\n",
      "  6.71 -0.36  0.06 -0.18  2.88 -0.12  3.36  6.8   1.2   3.36  5.31  3.29\n",
      " -0.35 -0.42 -0.31 -0.46 -0.39  0.54 -0.3  -0.28  0.07  3.59  0.08  1.76\n",
      "  2.55 -0.5  -0.27  3.13 -0.13 -0.43 -0.17  2.95  2.73  3.91  5.01 -0.35\n",
      "  1.39  1.66 -0.37  4.03 -0.68 -0.26 -0.32 -0.67]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_undersample_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.    0.    0.    0.    0.    0.01  0.01  0.01  0.01  0.07  0.07\n",
      "  0.07  0.07  0.09  0.09  0.19  0.19  0.26  0.26  0.26  0.26  0.43  0.43\n",
      "  0.54  0.54  0.6   0.6   0.79  0.79  0.84  0.84  0.92  0.92  1.  ]\n"
     ]
    }
   ],
   "source": [
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.39  0.41  0.44  0.46  0.82  0.82  0.84  0.84  0.9   0.9   0.92\n",
      "  0.92  0.93  0.93  0.94  0.94  0.95  0.95  0.95  0.95  0.96  0.96  0.97\n",
      "  0.97  0.97  0.97  0.98  0.98  0.99  0.99  0.99  0.99  1.    1.  ]\n"
     ]
    }
   ],
   "source": [
    "print(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.87  3.36  3.36  3.2   3.18  1.11  1.04  0.72  0.69  0.37  0.16  0.12\n",
      "  0.11  0.07  0.06  0.05 -0.14 -0.15 -0.18 -0.19 -0.19 -0.21 -0.31 -0.31\n",
      " -0.38 -0.38 -0.4  -0.4  -0.5  -0.51 -0.54 -0.54 -0.58 -0.59 -0.97]\n"
     ]
    }
   ],
   "source": [
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
