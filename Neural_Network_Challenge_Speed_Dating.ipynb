{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_dating_download = pd.read_csv('Speed Dating Data.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the original work from my capstone..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Classifier Accuracy = 0.8054740957966764\n",
      "Gradient Boosting Classifier Accuracy = 0.8054740957966764\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAAEWCAYAAAANXvnnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXm4FNW1t9+foCCIoML1QYNBjUNwRi5qnDBR4xCnG71m\nVKLRS9SgN/Hm80u8ahyiCfniEEkMGmOMxMQ5RhOUKISIIIIgiDhFMc6zCOKAsL4/9mopmtPndPfp\noc45632efqjatWvX6qLX2VV7//ZaMjOCIGgMazTbgCDoSoTDBUEDCYcLggYSDhcEDSQcLggaSDhc\nEDSQcLgmIWkTSUskdSuj7ghJz7dy/BpJ59fWwqAehMOVgaQJks5tofwwSS9L6l5pm2b2LzNbx8yW\n18bK6pBkkj7VTBsKSFooad9m21FPwuHK47fA1ySpqPzrwHgz+6iSxqpx0M5MV7of4XDlcRuwAbBn\noUDSesAXgGt9/2BJsyW9I+k5Sedk6g72nuR4Sf8C7s2Udfc635C0QNJiSU9L+q9iIyR9X9Lr3hN8\ntZSxkr4gaY6ktyXdL2n7cr6kpHMk3SjpOrdjnqQtJf1fSa/699o/U3+ypAslzfDv/SdJ62eOHypp\nvtsxWdKnM8cWSvo/kuYC70q6HtgE+LM/an/P693oTxGLJE2RtE2mjWskjZV0p9v7gKTNM8e3kTRR\n0puSXpH0fS9fQ9IZkv4p6Q1JN2TtritmFp8yPsCVwFWZ/f8C5mT2RwDbkf6IbQ+8AhzuxwYDRnLO\n3sDambLuXudgYHNAwN7AUmBopu2PgJ8BPfz4u8BWfvwa4Hzf3gl4FdgF6AYcCywEepT4XgZ8yrfP\nAd4HPg90d3ufAX4ArAmcADyTOXcy8AKwrX+vm4Hr/NiWbuN+fu73gKeAtfz4QmAOMAhYO1O2b5F9\nxwF9/HtfUnTPrwHeAIa7veOBP/ixPsBLwHeBnr6/ix87FZgOfMLb/RVwfUN+R83+IXeUD7AH8DbQ\n0/enAv/dSv1LgIt9u+Bcm2WOr+JwLZx/G3Cqbxccrnfm+A3A/2Z+eAWH+yVwXlFbjwN7l7hOscNN\nzBw7BFgCdPP9Pl6/n+9PBi7K1B8CfEhy9P8FbsgcW8Odc4TvLwSOK7JlNYcrOt7Pr983872zfwQP\nAh7z7S8Ds0u0swD4XGZ/ILCs1P9FLT/xSFkmZnYf8DpwuD+2DAd+XzguaRdJkyS9JmkRMAroX9TM\nc6Xal3SgpOn++PM26ceTPf8tM3s3s/8ssFELTX0S+K4/xr3tbQ0qUbclXslsvwe8bisHdt7zf9fJ\n1Ml+p2dJvVl/v96zhQNmtsLrblzi3NWQ1E3SRf7o9w7JIWHV+/JyZntpxrZBwD9LNP1J4NbM/VkA\nLAc2bM2eWhAOVxnXAscAXwPuMrPsj/P3wO3AIDPrC1xBejzM0uLSDEk9SI9jPwU2NLN+wF+Kzl9P\nUu/M/ibAiy009xxwgZn1y3x6mdn1ZX/LyhhUZNMy0h+mF0k/bAB8wGkQqZcrUHw/ive/AhwG7Av0\nJT0VwOr3tSWeAzZr5diBRfeop5m9UKJ+zQiHq4xrSf/5J5BGLrP0Ad40s/clDSf9WMplLdK7xGvA\nR5IOBPZvod4PJa0laU/SgM2NLdS5EhjlPa4k9fYBnT4V2FMJX5M0RFIv4FzgJu8RbwAOlvQ5SWuS\n3qU+AO5vpa1XWNVJ+vg5bwC9gB9VYNcdwEBJp0nqIamPpF382BXABZI+CSBpgKTDKmi7asLhKsDM\nFpJ+ML1JvVmWk4BzJS0GziL94MptdzEw2s95i+Ssxe2/7MdeJA0OjDKzx1poaybpD8LlXv8pYGS5\ntlTB70jvUi+TBidGux2Pk54Efk7q8Q4BDjGzD1tp60LgTH/UO530B+5ZUq/4KGmgoyz8nu7n130Z\neBLYxw9fSrq/d/v/13TSIFPdkb80BkHFSJpMGpW8qtm2dBSihwuCBhIOFwQNJB4pg6CBRA8XBA2k\ny4hG+/fvb4MHD262GUEnZdasWa+b2YC26nUZhxs8eDAzZ85sthlBJ0XSs23XikfKIGgo4XBB0EDC\n4YKggYTDBUEDCYcLggYSDhcEDSQcLggaSDhcEDSQLjPxPe+FRQw+485mmxF0YBZedHC724geLgga\nSN0crhAD0Lf7STqpjfpXe+zDR8po+yiPd7hC0rBa2BsEjaCePdz3M9v9SCEIVkMro+5eAxxQZtuP\nAP8BTKnWuCBoBjV5h5N0GykiU09SvIjNgLUlzQHmk+IUbu77E4E7gfNIMTe2BrY0symSBpdzPTNb\n4Ndty64TgRMBuq3bppA7COpOrQZNjjOzNyWtDTxIigx8ipntCCnUN7BtZn8EMNTLnqmRDathZuOA\ncQA9Bm4RK22DplMrhxst6QjfHgRsUcY5M+rpbEGQR9rtcN5b7QvsZmZLPZJTzzJOfbftKkHQuajF\noElfUhjupZK2Bnb18mUeABRgMSmoZxB0aWrxSDmBFOl3ASlpRCFY5zhgrqSHzOyrkqb6kP9fSYMm\nq+DpikYA/ZWyfZ5tZr9u6YL++PpzYABwp6Q5Zvb51ozcbuO+zKzBxGUQtIcuE7Vr2LBhFiEWgnoh\naZaZtTknHNKuICiDWsi6IOcOJ2kssHtR8aVm9ptm2BME7aVmShNJo5VS5o6v4twWpVpmdrKZ7Zj9\nALd7HrYlki6vlf1B0Ahq2cOdRMpe+XwV5xakWr8qo+77pOya2/onCDoMNenhJF1BknP91ZOfn545\n9ohSAvnB3gNe6b3Z3a5MwcwWeHqjNjGzdz0b6ftl2HWipJmSZi5fuqjKbxcEtaMmDmdmo0h5y/YB\nLm6l6hbAWDPbhpQv+4u1uH4rdo0zs2FmNqxbr771vFQQlEWj18M9Y2ZzfHsWK1PIBkGXoB4O91FR\nu1mZ1weZ7eXkfJQ0CGpNPX7wC0n5p5E0FNi0DteomFCaBHmgHj3czcD6kuYDpwBPtHWCpCNczrUb\nSap1Vxv1FwI/A0ZKel7SkPabHQT1p8tIu3oM3MIGHntJs80IckCtVCNZypV2RRChIGggFTucpPvL\nqHOapF5l1JtcUJZIukDSc5KW+P7nJc0p+tzqx/aS9JCkjyQdWel3CIJmUfGgiZl9poxqpwHXAUsr\naPrPwOXAk36du4BS73L/AkYCp5c4HgS5pJoertADjfAe6iZJj0kar8RoYCNgkqRJXnd/SdO8V7pR\n0jrF7ZrZdDN7qRwbzGyhmc0FVrRhayhNglzR3ne4nUi92RCStGt3M7sMV52Y2T6S+gNnknSWQ4GZ\nwHfaed2yCKVJkDfaOw83oyBW9hB4g4H7iursSnLIqR7Wbi1gWjuvGwQdkvY6XDnKEQETzezL7bxW\nEHR46jUtkA0aNB3YXdKnACT1lrRlna4bBLmmXlrGccAESS/6e9xI4HpJPfz4mRQpUCT9BPgK0MtV\nJ1eZ2TktNS7p34FbgfWAQyT90FcglCSkXUEe6DJKkwgiFNSTCCJURAQR6vjUQ5LVaHLtcJJ+ABxV\nVHyjmV3QDHuCoL00VEspaWSpwD8t5YczswuKgwiZ2QWRHy7oqORJvHwNkR8u6ORU5XCSbpM0y3uZ\nE71siaQxXvY3ScNd+vW0pEMzpw/y8iclnV0oNLMpwJvlXL/coEMh7QryRrU93HFmtjMwjJSqagOg\nN3CvD88vBs4H9gOOAM7NnDucFDxoe+Coej4ShrQryBvVDpq0lA/uQ1JiD4B5wAdmtkzSPFYNFjTR\nzN4AkHQLsAdJXxkEnZ6KHU6l88Ets5WTeitw2ZeZrdDKPN4AxRN/XWMiMAiorocrlQ+uXPaTtD7w\nHnA4cFwVNlRMKE2CPFDNO9wEoLtSPriLWJkPrlxmkAINzQVuNrOZ8HF+uGnAVh4Y6PhSDVQadCgI\n8kKXkXZFEKGOR0dSlkQQoSDIITV1OElXVRsjsiWliaSxLQQS+kYoTYKOSk21lGb2zXacfg0piNC1\nmfZObqmipE9TfnqrIMgNVfdwvpD0TkkPK6WkOroo7N0SD333sKTpkjb08g0l3erlD0v6DNRHaRIE\neaM9j5QHAC+a2Q5mti0rJ70L9Aamm9kOJM3jCV5+GfB3Lx8KzG+HDa0S0q4gb7TH4eaR5tR+LGlP\nMyv+RX8I3OHb2dRUnwV+CWBmy1s4r2aEtCvIG1W/w5nZE0rZcQ4Czpd0T1GVrPIkUlMFAe17h9sI\nWGpm1wFjSI+H5XAP8C1vo5uk6HqCLkN7ep3tgDGSVgDLSE700zLOOxUY50qS5X7eNFeajAD6u4rk\nbDP7dUsNuHD658AAktJkjpl9vlVjQ9oV5IAuozSJIEJBPYkgQkVEEKHm05GkWvUi1w4naSywe1Hx\npWb2m2bYEwTtpSYOp5QCeJiZvd6ONiaQlvrcZ2ZfgFaVJqeQkohsDgxoz3WDoJE0XbycWZw6Bvh6\nmadNJS2CfbYuRgVBnagmP9xqki4/9G2l/G/zfGEqHkhomqTZku6XtJWXj5R0u6R7SdMEmNk9pFgo\nbWJms81sYRm2htIkyBXV9HClJF2ve/63X7IyM+ljwJ5mthNwFvCjTDtDgSPNbO/qTG+bUJoEeaMa\nhysl6brF/83KuPoCN/qSm4uBbMKNiWZWllg5CDoLFTucmT1B6p3mkSRdZ/mhQq64rIzrPGCS94SH\nkIINFXi3KouDoANTTdSujYA3zew6SW8Dra2B6wu84NsjKzevdoTSJMgD1TxSbgfMUEoxfDYp4Gsp\nfgJcKGk2bTi3pH8ANwKf8yBCJaVakka7/OsTwFxJV1X6JYKgGXQZaVcEEao9oRxZSacJIiTp+5nt\nfpJOaqY9QdAe8i7tuhU4VNJ/etFaQC/gFy3U7W5mHzXSviColFw5nKTbSLkKegKXAtm4JfOBbsBh\n/v44EbiTNBL6FrA1sGVDDQ6CCsmVw5Gy8rwpaW3gQWBv4BQz2xFA0mBg28z+CNIUxbZm9kxTLA6C\nCsibw7WUlactZpRyNqXcdScCdFt3QG0sDIJ2kJtBk6KsPDsAs1l1orwUJSfQQ9oV5I3cOByls/Is\nk7Smby8G+jTFuiCoAXlyuFJZecaRJrfHeyLHqb5KYUyzDA2CaukyE98R0ySoJ51m4jsIOhN5G6Ws\nGxFEaCUhyWoeuenhJC3xfzeSdJNvj5R0eXMtC4LakbsezsxeBI5sth1BUA9y08MVkDQ4m5QxU36w\nx0fpL2mApJslPeif4lB6QZBLctfDtYSrT74DHGRmb0n6PXCxmd0naRPgLuDTLZwXSpMgV3QEh/ss\nMAzY38ze8bJ9gSGSCnXWlbSOmS3Jnmhm40jzePQYuEXXmP8Ick1HcLh/ApuRVgIUJtLWAHY1s/eb\nZlUQVEHu3uFa4Fngi8C1kgpRv+4Gvl2oIGnHZhgWBJXSEXo4zOwxSV8lhdw7BBgNjJU0l/QdpgCj\nWmsjgggFeSCkXUFQAyJdVRGdVWkSqpGORa7e4SQtlNS/2XYEQb3IlcO1h0wWniDILU1zuHpl4QmC\nPNPMHq7DZOEJglrRTIerexaeyA8X5I2mOVwjsvBEEKEgbzRtoKGjZuEJgvbQzEfKumThCYI8E0qT\nIKgBEUQoCHJIl3k868jSrpBvdR5y18N5dtMFksY325YgqDV57OFOAvY1s+ebbUgQ1Jpc9XCSriCt\n7v6rpEWSTs8ce8QDDA32HvBKSfMl3e3prYIg9+TK4cxsFPAisA9JUVKKLYCxZrYN8DZpRfhqhNIk\nyBu5crgKeMbM5vh2VgK2CqE0CfJGnh3uI1a1Lyvn+iCznZWABUGuybPDLSRpLZE0FNi0qdYEQQ3I\nc89wM3CMpPnAA8AT7WksgggFeSB3DmdmgzO7+5eotm2m/k/ralAQ1JDcOVy96IhKk1CYdD6aGWLh\n/jLqnCapVxn1JktqUzgaBM2mmQtQP1NGtdOANh0uCDoKzezhCgkYR3gPdZOkxySNV2I0sBEwSdIk\nr7u/BxN6SNKNktZplv1BUA15mRbYidSbDSFJu3Y3s8tw1YmZ7ePxKs8k6SyHkhJ7fKdZBgdBNeRl\n0GRGQazsK8AHA/cV1dmV5JBTPU3VWsC01hqN/HBB3siLw5WjHBEpQteXy2008sMFeSMvj5SlWAz0\n8e3pwO6SPgUfB5LdsmmWBUEV5N3hxgETJE0ys9dIEbuu9zRV04Ctm2lcEFRKBBEKghoQQYSCIIfk\nZdCk7uRd2hUyrq5BLns4SVdJGtJsO4Kg1uSyhzOz1sKeB0GHpek9XEt54rJiZElLJF3gx6dL2tDL\nN5R0q5c/LKkcbWYQNJWmOxyl88QV6A1MN7MdgCnACV5+GfB3Lx8KzC9uOIIIBXkjDw5XKk9cgQ+B\nO3w7GzDos6SkjZjZ8hbOiyBCQe5o+jucmT3hMUsOIuWJK04dvMxWThZGwKCgQ9P0Hs7zxC01s+uA\nMXjgoDK4B/iWt9FNUnRhQe7JQ2+xHTBG0gpgGcmJyolTciowTtLxpJ7vW7SyeiCCCAV5IKRdQVAD\nypV25aGHawh5UJqEmiRo+jtcNUgaKenyZtsRBJXSIR0uCDoqTXU4SbdJmuVpp070siWSxnjZ3yQN\nd+XJ05IOzZw+yMuflHR2k75CEFREs3u448xsZ2AYMFrSBiRlyb2eimoxcD6wH3AEcG7m3OGkNFXb\nA0dFXMqgI9DsQZPRko7w7UGkvG8fslLeNQ/4wMyWSZrHqmmpJprZGwCSbgH2IEXy+pgIIhTkjWbG\npRwB7Avs5nrI2aSUVFllyQo8wJCZrWDVPxDF8xmrzW+EtCvIG818pOwLvGVmSyVtTQqDVwn7SVrf\n0w0fDkytuYVBUGOa6XATgO6SFgAXkaJyVcIMUkqrucDNZhaz2kHuCaVJENSACCIUBDmk2aOUDaPZ\n0q6QdQWQ4x5O0jWSjmy2HUFQS3LrcJUiqcv01kHHpSYOJ+l/JT0u6T5J10s6XdLmkia4dOsfPvRf\n6Lkuk3S/y7WO9HJJutzb+Rvwb5n2d5b0d2/rLkkDvXyypEskzSStjwuCXNPuXkHSv5MkVjsAawIP\nkWKPjANGmdmTknYBfkGKQwIwkKQM2Rq4HbiJJN3aipSSakPgUeBqSWsCPwcOM7PXJB0NXAAc522t\nVWp0KJQmQd6oxWPY7sCfzOx94H1JfyYpRj4D3Oi53AB6ZM65zZUjjxbC3gF7Adeb2XLgRUn3evlW\nwLbARG+rG/BSpq0/ljIs0lUFeaNe7z1rAG+b2Y4ljmfzwalEnezx+Wa2W4nj71ZqXBA0i1q8w00F\nDpHU03NufwFYCjwj6Sj4+P1shzbamQIc7QGBBgL7ePnjwABJu3lba0rapgZ2B0HDaXcPZ2YPSrqd\nJLF6haTwXwR8FfilpDNJ73Z/AB5upalbSe94jwL/wgMCmdmHPrBymUfm6g5cQguBX1sjgggFeaAm\n0i5J65jZEkm9SD3ViWb2ULsbriEh7QrqSaODCI3zbDc9gd/mzdmg/kqTUJIE5VCTeTgz+wpwg5lt\nbWYXSuon6aRatB0EnYlaKk2+n9nuB7TocKEICboyVf34Jd1GConQE7gU2AxYW9Ic0mBGN2Bz358I\n3AmcB7xFmuzesoU2B5PWyM1iZTacY3yB6kXAocBHwN1mdrqPgJ5Nirq8yMz2qua7BEEjqba3Oc7M\n3vTV1g8CewOnFObd3Hm2zeyPIDnRtmb2TCvtbgUcb2ZTJV0NnCTpNyQVytZmZpL6ed2zgM+b2QuZ\nsiDINdU+Uo6W9DBplXYh+E9bzGjD2QCeM7NCqITrSPKvRcD7wK8l/Qdpjg/S/N81kk4g9airEfnh\ngrxRscO1EvynLcpRhKwWGMjMPiKFxLuJNKk+wQ+MAs4kOfwsD7FXfHIEEQpyRTWPlKWC/yyTtKaZ\nLSPFk+xTRdubSNrNzKYBXwHuc/VKLzP7i6SpwNMAkjY3sweAByQdSHK8N6q4ZhA0jGoeKUsF/xkH\nzJU03uNFTlXK2T2mgrYfB072ttcjZTjtA9whaS5wH/AdrztG0jxJjwD307qKJQhyQW6CCPlAyx2e\n57vmhNIkqCcRRCgIckjDJ6F9cKM4jzfA5+rVu0HtpV0h5QqqoeEO5+93pdbJBUGnpupHSkmjJS2Q\nNL6WBgVBZ6Y9PdxJwL5m9nytjAmCzk5VPZykK0j6yb9KWiTp9MyxRyQN9s8CSVcqJVe826Vgpdqc\nLOlSSXO8jeFevreXzZE0W1IfSQMlTcnU3bNEm6E0CXJFVQ7nKo8XSWEQLm6l6hbAWE+u+DYpuldr\n9HL95UnA1V52OnCyl+8JvEeaFL/Ly3YA5pSwM5QmQa6o97TAM2ZWcIZZrJpQsSWuBzCzKcC6Lkqe\nCvxM0mign0u9HgS+IekcYDszW1wP44Og1tTC4T4qaierq8xG51pO2++MLWkpLwK+CaxNUq9s7Q65\nF/ACScB8TFWWB0GDqcW0wEKSqBhJQ4FN29HW0cAkSXuQ1rgtcs3kPGCeB53dWtJ7wPNmdqWkHqSl\nP9e21nAEEQryQC0c7mbgGEnzgQeAJ9rR1vuSZpOifBUiK58maR9S+uH5wF+BLwH/I2kZsASIHi7o\nEORJSzkZOL1emUx7DNzCBh57SbvbCYVJ0BKhpQyCHFJXaZekkcAwMzslUzaWlI8gy6VmNqKetgRB\nHmiGlvLkRl8zCPJCWY+Ukm5Tys0231NAIWmJpDFe9jdJw10t8rSkQzOnD/LyJyWd3co1Bkt6TNJ4\nV6jc5JGckXSRpEclzZX0Uy87ylUmD0ua0o57EAQNo9x3uOPMbGdgGCmA0AZAb+BeV5EsBs4H9iNF\n2Do3c+5wksJke+AoSa29WG4F/MLMPg28Q4ratYG3uY2Zbe/XgZVRu3YghdBbjZB2BXmjXIdrKUrX\nh3hAH1ICj797PJN5rKoomWhmb5jZe8AtpEhcpahp1K6QdgV5o02HayVK1zJbOaewAleVeKLF7Lvh\nauqRVi5X06hdQZA3yunhSkXpKpf9JK3vKwUOJ/VMpdhEngeOVaN29TWzvwD/TRIrfxy1y8zOAl4j\nOV4Q5JpyRiknAKM8ktbjrIzSVS4zSGqUTwDXtTGxXYjadTUpT9wvSQ7/J0k9SdlQs1G7tvCye2gj\naldIu4I8kCelyWAialfQQSlXadJlMtnUKohQSLuC9tBlonYFQR4oZ5Ty/jLqnFaYpG6j3mRgUzPb\nsYVPhCkPOj1tOpyZfaaMdk4D2nS4IOjqlNPDLfF/R7hE66aMBEse+mAj0sLRSV53f0nTJD0k6UYf\n2m8Tl4td7HKxeyQN8PLRGWnXH7xsteBCLbQXSpMgV1S6PGcnUm82hBS1a3czuwwPKGRm+0jqT5qQ\n3tfMhgIzWTmU3xa9gZkuF/s7KcMpwBnATi7tGuVlLQUXWoVQmgR5o1KHm2Fmz7uaZA4tBwXaleSQ\nU5VSDh8LfLLM9lcAf/TtgrQLYC4wXtLXSDFUoOXgQkGQayp1uHKCAomknywMhgwxs+OrtK8wSXgw\nMJYUu+RBSd1bCi5U5TWCoGHUalqgkIDxdZISZaykT5nZU5J6AxubWTmxTtYAjgT+wEpp1xrAIDOb\nJOk+UjyTdSRtUBxcCHisVMOhNAnyQK0cbhwwQdKL/h43ErjeI2pBeqcrx+HeBYZLOhN4lRTFqxtw\nnaS+pN7zMjN7W9J5LQQXCoJckxtpF6RRSjMra0SzUkLaFdSTkHYV0ZK0K2RaQaNpl8NJugr4mZk9\nWuF5DwA9ioq/Xq/eLQjyQrsczsy+WeV5u7TnukHQUSl7WkBSb0l3etCeRyQd7cqTYX58iaQL/Ph0\nSRt6+YaSbvXyhyW1KBWLIEJBV6CSebgDgBfNbAdX9U8oOt4bmO5hGKYAJ3j5ZaR4JzuQ5tHmt3KN\nCCIUdGoqcbh5pHAJP5a0p5kV/4I/BO7w7Wxqqs+SVm5jZstbOC9LBBEKOjVlO5xPXA8lOd75ks4q\nqpINKlROaqoWL7P6ZSOIUNB5qOQdbiNgqZldB4whOV853AN8y9vo5hPYpYggQkGnppJeaDtS4J4V\nwDKSE/20jPNOBcZJOp7U830LmFaibgQRCjo1uVGaRBChoCNTrtIk0lUFQQOJIEJB0ECaka7qDWDH\nRl83CPJAPFIGQQMJhwuCBhIOFwQNJBwuCBpIOFwQNJDcTHzXG0mLSUqWvNCfFHQpT+TNpo5kzyfN\nbEBbDXSZEAvA4+UoARqFpJl5sgfyZ1NntCceKYOggYTDBUED6UoON67ZBhSRN3sgfzZ1Onu6zKBJ\nEOSBrtTDBUHTCYcLggbSJRxO0gGSHpf0lKQzmnD9QZImeai/+ZJO9fJzJL2QSSx5UANtWihpnl93\nppetL2mipCf93/UaZMtWmXswR9I7SmmsG3p/JF0t6VVJj2TKWrwnSlzmv6m5ksoLOWJmnfpDiuj1\nT1ICybVIoRiGNNiGgcBQ3+5DSmwyBDgHOL1J92Uh0L+o7CfAGb59BvDjJv1/vUzKKdjQ+wPsRYrV\n80hb9wQ4iJRARqSciA+Uc42u0MMNB54ys6fN7ENSKqzDGmmAmb1kZg/59mJgAbBxI20ok8OA3/r2\nb4HDm2DD54B/mtmzjb6wmU0B3iwqLnVPDgOutcR0oJ+kgW1doys43MbAc5n952nij91jt+wEPOBF\np/gjydWNeoRzDLhb0ixJJ3rZhmb2km+/DGzYQHsKfAm4PrPfrPtToNQ9qep31RUcLjd4yL+bgdPM\n7B1SVLLNSSvgXwL+XwPN2cNSDvYDSZHS9soetPTc1NA5I0lrkaJo3+hFzbw/q1GLe9IVHO4FVo1Z\n+QkvayiS1iQ523gzuwXAzF6xFI16BXAl6fG3IZjZC/7vq8Ctfu1XCo9F/u+rjbLHORB4yMxecdua\ndn8ylLonVf2uuoLDPQhsIWlT/wv6JeD2RhogScCvgQVm9rNMefaZ/wjgkeJz62RPb0l9CtvA/n7t\n24FjvdqxwJ8aYU+GL5N5nGzW/Smi1D25HTjGRyt3BRZlHj1L0+hRqGZ8SCNKT5BGK3/QhOvvQXoU\nmQvM8c9BwO9IoePn+n/gwAbZsxlptPZhUnKVH3h5IaLak8DfgPUbeI96A2+QomwXyhp6f0jO/hIp\n0PHzwPFtcBpNAAADvUlEQVSl7glpdHKs/6bmAcPKuUZIu4KggXSFR8ogyA3hcEHQQMLhgqCBhMMF\nQQMJhwuCBhIOVwckLXd1+yOS/iypXxnnLGnjeD9JJ2X2N5J0Uw1sHZxVxzcCSTs2cmVEngiHqw/v\nmdmOlrIBvQmcXIM2+wEfO5yZvWhmR9ag3YYiqTtJqhUOF9SFaWRErZL+R9KDLsj9YXFlSetIukfS\nQ75erbCy4SJgc+85x2R7JknTJW2TaWOypGGuKLla0gxJszNttYikkZJu83VfCyWdIuk7fu50Setn\n2r8004sP9/L1/fy5Xn97Lz9H0u8kTSVNZp8LHO3nHy1puKRpfp37JW2VsecWSRN8PdpPMrYe4Pfo\nYUn3eFlF37cpNFp10RU+wBL/txtJiHuA7+9PCkQj0h+7O4C9is7pDqzr2/2Bp7z+YFZdp/XxPin3\n+Q99eyApBifAj4Cv+XY/ktqmd5Gt2XZG+vX6AAOARcAoP3YxSXQNMBm40rf3ypz/c+Bs3/4sMMe3\nzwFmAWtnrnN5xoZ1ge6+vS9wc6be06S00z2BZ0n6xQEkpf6mXm/9cr9vsz9dKRBsI1lb0hxSz7YA\nmOjl+/tntu+vA2wBTMmcK+BHrt5f4W20tUzmBuBu4GzgP4HCu93+wKGSTvf9nsAmblMpJllas7dY\n0iLgz14+D9g+U+96SGvIJK3r76l7AF/08nslbSBpXa9/u5m9V+KafYHfKuVsN2DNzLF7zGwRgKRH\nSQtT1wOmmNkzfq3CGrZqvm9DCYerD++Z2Y6SegF3kd7hLiM504Vm9qtWzv0q6S/4zma2TNJC0g+n\nJGb2gqQ3/BHuaGCUHxLwRTOrJMT7B5ntFZn9Faz6eynWBLalEXy3lWPnkRz9CF8vOLmEPctp/Tdb\nzfdtKPEOV0fMbCkwGviuDxbcBRzn6+KQtLGkfys6rS/wqjvbPqS/6ACLSY96pfgj8D2S+Heul90F\nfNtXKyBpp1p8L+dob3MPklJ+EfAP0h8MJI0AXre07q+Y4u/Sl5VLW0aWce3pwF6SNvVrre/l9fy+\nNSEcrs6Y2WyS2v3LZnY38HtgmqR5pEe/YicaDwzz48cAj3k7bwBTfZBiTAuXuom09OiGTNl5pMez\nuZLm+36teF/SbOAKkqoe0rvazpLmkgZ5ji1x7iRgSGHQhBQ35EJvr82nLjN7DTgRuEXSw6Q/NlDf\n71sTYrVAUDGSJpOC+8xsti0djejhgqCBRA8XBA0kerggaCDhcEHQQMLhgqCBhMMFQQMJhwuCBvL/\nASzesN2qstS8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10daad518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1 - Attribute Importance\n",
      "_pss - Partner's Self Score\n"
     ]
    }
   ],
   "source": [
    "speed_dating2 = speed_dating_download.copy()\n",
    "\n",
    "self_scores = speed_dating2[['iid','pid','attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1']]\n",
    "speed_to_merge = speed_dating2[['iid','pid','attr1_1','amb1_1','sinc1_1','intel1_1','fun1_1',\n",
    "                                'shar1_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like',\n",
    "                                'dec','gender']]\n",
    "self_scores.columns = ['pid', 'iid','attr_pss','sinc_pss','intel_pss','fun_pss','amb_pss']\n",
    "self_scores.head()\n",
    "\n",
    "merged =  pd.merge(self_scores, speed_to_merge, on=['iid', 'pid'])\n",
    "merged = merged.dropna()\n",
    "\n",
    "speed_dating2 = merged.sample(frac=1)\n",
    "\n",
    "train, test = train_test_split(speed_dating2, test_size = 0.3)\n",
    "\n",
    "\n",
    "train_X = train[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like',\n",
    "                 'attr_pss','sinc_pss','intel_pss','fun_pss','amb_pss','attr1_1',\n",
    "                 'amb1_1','sinc1_1','intel1_1','fun1_1','shar1_1','gender']]# taking the training data input \n",
    "train_y= train.dec# This is output of our training data\n",
    "\n",
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "test_X = test[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', \n",
    "                 'attr_pss','sinc_pss','intel_pss','fun_pss','amb_pss',\n",
    "               'attr1_1','amb1_1','sinc1_1','intel1_1','fun1_1',\n",
    "               'shar1_1','gender']]# taking the training data input \n",
    "test_y = test.dec# This is output of our training data\n",
    "\n",
    "\n",
    "\n",
    "model=RandomForestClassifier(n_estimators=100)# a simple random forest model\n",
    "\n",
    "model.fit(train_X,train_y)\n",
    "\n",
    "prediction = model.predict(test_X)\n",
    "\n",
    "print('Random Forrest Classifier Accuracy = {}'.format(metrics.accuracy_score(prediction,test_y)))\n",
    "\n",
    "pred_y = clf.predict(test_X)\n",
    "\n",
    "# Accuracy table.\n",
    "# table = pd.crosstab(test_y, pred_y)\n",
    "\n",
    "print(\"Gradient Boosting Classifier Accuracy = {}\".format(metrics.accuracy_score(pred_y,test_y)))\n",
    "\n",
    "\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, train_X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()\n",
    "\n",
    "print('1_1 - Attribute Importance\\n_pss - Partner\\'s Self Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based off of this, I created a neural network. It was slightly more accurate, but I had 2 layers of 1000 neurons each!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 1000), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,1000))\n",
    "mlp.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80620155038759689"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm going to do it again using the entire data set and then doing a cross-validation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = speed_dating2[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like',\n",
    "                 'attr_pss','sinc_pss','intel_pss','fun_pss','amb_pss','attr1_1',\n",
    "                 'amb1_1','sinc1_1','intel1_1','fun1_1','shar1_1','gender']]# taking the training data input \n",
    "Y = speed_dating2.dec# This is output of our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1000, 1000), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2 = MLPClassifier(hidden_layer_sizes=(1000,1000))\n",
    "mlp2.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80041061739257957"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's interesting that the initial score is slightly lower... Now to try some cross validation scores... These are also lower... I wonder if it has to do with not having a lot of data to work with... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77785924,  0.77492669,  0.79545455,  0.79692082,  0.79897285])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp2, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed the alpha to 0.001 and the layers to 2 layers of 100 neurons each. It ran much faster and actually is about the same in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3 = MLPClassifier(hidden_layer_sizes=(100,100), alpha=0.001)\n",
    "mlp3.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81052940313829003"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77859238,  0.77639296,  0.78445748,  0.80205279,  0.79823918])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp3, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I tried changing the activation function to sigmoid ('logistic')... It was slightly worse... :-/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4 = MLPClassifier(hidden_layer_sizes=(100,100), alpha=0.001, activation= 'logistic')\n",
    "mlp4.fit(X,Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78266608007039151"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76392962,  0.77199413,  0.77565982,  0.79618768,  0.76889215])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mlp4, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
